{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9dbc516",
   "metadata": {},
   "source": [
    "# 04 - Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f7becc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8228724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 12:19:57.355515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_roc_curve\n",
    "\n",
    "import shutil\n",
    "import cv2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b3b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, regularizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator;\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras_tuner import RandomSearch, GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4e699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seeds\n",
    "np.random.seed(132)\n",
    "tf.random.set_seed(132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41800b5",
   "metadata": {},
   "source": [
    "# 1.0 Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd16b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images from preprocessing stage\n",
    "images = np.load('/Users/chinmayasukumar/Documents/Springboard/Capstone 3 - Metal defect detection/data/interim/images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a12a5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataframe\n",
    "df = pd.read_csv('/Users/chinmayasukumar/Documents/Springboard/Capstone 3 - Metal defect detection/data/interim/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78e2eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "035f07f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Number</th>\n",
       "      <th>Type_Crazing</th>\n",
       "      <th>Type_Inclusions</th>\n",
       "      <th>Type_Patches</th>\n",
       "      <th>Type_Pitted</th>\n",
       "      <th>Type_Rolled</th>\n",
       "      <th>Type_Scratches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cr_1.bmp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cr_10.bmp</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cr_100.bmp</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cr_101.bmp</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cr_102.bmp</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename  Number  Type_Crazing  Type_Inclusions  Type_Patches  \\\n",
       "0    Cr_1.bmp       1             1                0             0   \n",
       "1   Cr_10.bmp      10             1                0             0   \n",
       "2  Cr_100.bmp     100             1                0             0   \n",
       "3  Cr_101.bmp     101             1                0             0   \n",
       "4  Cr_102.bmp     102             1                0             0   \n",
       "\n",
       "   Type_Pitted  Type_Rolled  Type_Scratches  \n",
       "0            0            0               0  \n",
       "1            0            0               0  \n",
       "2            0            0               0  \n",
       "3            0            0               0  \n",
       "4            0            0               0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f43115ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating labels, converting to array\n",
    "labels = df.iloc[:,2:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c5d0870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bf000ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e69d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 200, 200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ed605",
   "metadata": {},
   "source": [
    "#### There are 1800 200x200 images with 6 possible categories corresponding to the type of steel defect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9b913",
   "metadata": {},
   "source": [
    "# 2.0 Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0344a",
   "metadata": {},
   "source": [
    "## 2.1 Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "853f63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to (1800, 200, 200, 1) to account for black/white channel\n",
    "images = images.reshape(-1,200,200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "459c0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and (test, valid) sets to be split further\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(images, labels, test_size=0.3, random_state=132)\n",
    "\n",
    "# Splitting (test, valid) set into seperate test and valid sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ce0a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1260, 200, 200, 1), (270, 200, 200, 1), (270, 200, 200, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shapes\n",
    "(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf747b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1260, 6), (270, 6), (270, 6))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shapes\n",
    "(y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb355ca",
   "metadata": {},
   "source": [
    "## 2.2 ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fe085cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ResNet model\n",
    "# input_tensor has shape (200, 200, 3) since ResNet only takes RGB images\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(200, 200, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5731014",
   "metadata": {},
   "source": [
    "### Transforming Grayscale to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "89973da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating images so they appear RGB\n",
    "# np.repeat repeats X_train's last column which is the column added for grayscale\n",
    "X_train_rgb = np.repeat(X_train, 3, -1)\n",
    "X_test_rgb = np.repeat(X_test, 3, -1)\n",
    "X_val_rgb = np.repeat(X_val, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6299ee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1260, 200, 200, 3), (270, 200, 200, 3), (270, 200, 200, 3))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rgb.shape, X_test_rgb.shape, X_val_rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a0c23",
   "metadata": {},
   "source": [
    "### Training ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e5208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 114s 3s/step - loss: 1.8344 - accuracy: 0.1595 - val_loss: 1.8038 - val_accuracy: 0.1444\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 107s 3s/step - loss: 1.8254 - accuracy: 0.1651 - val_loss: 1.7963 - val_accuracy: 0.1519\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 127s 3s/step - loss: 1.8093 - accuracy: 0.1556 - val_loss: 1.8163 - val_accuracy: 0.1519\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 138s 3s/step - loss: 1.8249 - accuracy: 0.1722 - val_loss: 1.8141 - val_accuracy: 0.1704\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 113s 3s/step - loss: 1.8146 - accuracy: 0.1698 - val_loss: 1.8232 - val_accuracy: 0.1444\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 121s 3s/step - loss: 1.8121 - accuracy: 0.1603 - val_loss: 1.8018 - val_accuracy: 0.1704\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.8155 - accuracy: 0.1595"
     ]
    }
   ],
   "source": [
    "x = layers.GlobalAveragePooling2D()(resnet_model.output)\n",
    "\n",
    "\n",
    "output = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=resnet_model.input, outputs=output)\n",
    "\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_rgb, y_train, epochs=10, validation_data=(X_val_rgb, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8f4cd",
   "metadata": {},
   "source": [
    "### Evaluating ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078843b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions\n",
    "y_pred_res = model.predict(X_test_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting classes of predictions\n",
    "y_pred_classes = np.argmax(y_pred_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classes\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaed081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting classification report with labels\n",
    "labels = labels=['Crazing', 'Inclusions', 'Patches', 'Pitted', 'Rolled', 'Scratches']\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=labels, zero_division=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6972373",
   "metadata": {},
   "source": [
    "#### This model will be put on hold while CNN is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de99119",
   "metadata": {},
   "source": [
    "## 2.3 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36ab003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a CNN model and returns it\n",
    "def create_model():    \n",
    "    model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(6, activation='softmax')\n",
    "            ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0db41644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits model to training data (input) and validates on valuation data\n",
    "# Callbakcs include patience of 4 and to restore best weights\n",
    "# Returns history\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val),\\\n",
    "                                callbacks=[EarlyStopping(patience=4, restore_best_weights=True)])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7451b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating base CNN model\n",
    "base_cnn = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61de3fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 84s 2s/step - loss: 1.5803 - accuracy: 0.3056 - val_loss: 1.3718 - val_accuracy: 0.3519\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 68s 2s/step - loss: 0.9392 - accuracy: 0.6317 - val_loss: 0.7641 - val_accuracy: 0.7074\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 78s 2s/step - loss: 0.6895 - accuracy: 0.7373 - val_loss: 0.5428 - val_accuracy: 0.8000\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 79s 2s/step - loss: 0.3950 - accuracy: 0.8706 - val_loss: 0.3556 - val_accuracy: 0.8778\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 80s 2s/step - loss: 0.5125 - accuracy: 0.7968 - val_loss: 0.6789 - val_accuracy: 0.6704\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 90s 2s/step - loss: 0.2997 - accuracy: 0.9008 - val_loss: 0.3009 - val_accuracy: 0.8889\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 72s 2s/step - loss: 0.1965 - accuracy: 0.9310 - val_loss: 0.3032 - val_accuracy: 0.8963\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 74s 2s/step - loss: 0.3095 - accuracy: 0.8865 - val_loss: 0.3149 - val_accuracy: 0.8778\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 63s 2s/step - loss: 0.3712 - accuracy: 0.8722 - val_loss: 0.4248 - val_accuracy: 0.8630\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 51s 1s/step - loss: 0.2146 - accuracy: 0.9310 - val_loss: 0.2311 - val_accuracy: 0.9185\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 50s 1s/step - loss: 0.1219 - accuracy: 0.9587 - val_loss: 0.1936 - val_accuracy: 0.9222\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.1010 - accuracy: 0.9659 - val_loss: 0.2093 - val_accuracy: 0.9296\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 56s 1s/step - loss: 0.0938 - accuracy: 0.9730 - val_loss: 0.1583 - val_accuracy: 0.9481\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 56s 1s/step - loss: 0.1551 - accuracy: 0.9405 - val_loss: 1.0267 - val_accuracy: 0.6926\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 81s 2s/step - loss: 0.4543 - accuracy: 0.8556 - val_loss: 0.2623 - val_accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "# Training model \n",
    "# Instantiating hist_base_cnn as the history returned from the train_model function\n",
    "hist_base_cnn = train_model(base_cnn, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67a768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returns plot of Accuracy and Loss for training and validation sets\n",
    "def grapher(history, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b4e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grapher(hist_base_cnn, 'Base CNN Training progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16d45f",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn_base = base_cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred_cnn_base, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels=['Crazing', 'Inclusions', 'Patches', 'Pitted', 'Rolled', 'Scratches']\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b0df0",
   "metadata": {},
   "source": [
    "#### Inclusions, Patches, Pits and Scratches aren't classified properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715be1f",
   "metadata": {},
   "source": [
    "#### Classes Crazing, Pitted and Scratches don't have very good f1-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c764cd9",
   "metadata": {},
   "source": [
    "## 3.0 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7e818",
   "metadata": {},
   "source": [
    "## 3.1  Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5349710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another CNN for hyperparameter tuning\n",
    "# Learning rate and optimizers (Adam or SGD) will be chosen as hyperparameters\n",
    "\n",
    "def create_model_1(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "    # Optimizer can be changed\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'sgd'])\n",
    "    \n",
    "    # Learning rate can be changed\n",
    "    learning_rate = hp.Float('learning_rate', 0.0001, 0.01, sampling='log', default=0.001)\n",
    "\n",
    "    # Conditional statement depending on which optimzier is chosen during Random Search\n",
    "    if optimizer == 'adam':\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy',\\\n",
    "        metrics=['accuracy'])\n",
    "    # If the chosen optimizer is SGD, the model will use a SGD with whichever learning rate is chosen\n",
    "    else:\n",
    "        model.compile( optimizer=keras.optimizers.SGD(learning_rate),loss='categorical_crossentropy',\\\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree('my_tuner_directory', ignore_errors=True)\n",
    "\n",
    "# Creating RandomSearch object \n",
    "tuner = RandomSearch(create_model_1, objective='val_accuracy', max_trials=10, executions_per_trial=1, \\\n",
    "                     directory='my_tuner_directory', project_name='image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750bed1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running Random Search\n",
    "tuner_hist = tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), \\\n",
    "             callbacks=[EarlyStopping(patience=3, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91323c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc8235",
   "metadata": {},
   "source": [
    "## 3.2 Round 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579ffb6",
   "metadata": {},
   "source": [
    "#### The best optimizer is Adam with a learning rate >0.00016. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc40a03",
   "metadata": {},
   "source": [
    "#### The best performing learning rate in the first search was ~0.0004. The default learning rate of the Adam optimizer is 0.001 so it makes sense to do a Grid Search between ~0.0004 and 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new model with Adam optimizer and tuning for learning rate only\n",
    "def create_model_2(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "    # Learning rate range for Grid Search is listed below\n",
    "    learning_rate = hp.Float('learning_rate', 0.000432025255103857, 0.0015, step=0.00007)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate),loss='categorical_crossentropy',\\\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree('my_tuner_directory_2', ignore_errors=True)\n",
    "\n",
    "# A GridSearch object is now generated \n",
    "tuner_2 = GridSearch(create_model_2, objective='val_accuracy', max_trials=15, executions_per_trial=1, \\\n",
    "                     directory='my_tuner_directory_2', project_name='image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_2_hist = tuner_2.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), \\\n",
    "             callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed6521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner_2.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary of learning rates and corresponding accuracies\n",
    "df_dict = {'Learning rate':[0.0007820252551038569, 0.001062025255103857, 0.000922025255103857, 0.001132025255103857,\\\n",
    "                 0.000572025255103857, 0.000992025255103857, 0.000432025255103857, 0.0012720252551038569,\\\n",
    "                 0.0006420252551038569, 0.000502025255103857],\n",
    "           'Accuracy':[0.9740740656852722, 0.9740740656852722, 0.9592592716217041, 0.9592592716217041, 0.9555555582046509,\\\n",
    "                       0.9555555582046509, 0.9407407641410828, 0.9407407641410828, 0.9370370507240295, 0.9370370507240295]\n",
    "\n",
    "          };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe on dictionary\n",
    "hyp_df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Plotting values except for learning rates with highest accuracy\n",
    "plt.scatter(hyp_df['Learning rate'].iloc[2:], hyp_df['Accuracy'].iloc[2:], color='blue')\n",
    "\n",
    "# Plotting highest learning rate values\n",
    "plt.scatter(hyp_df['Learning rate'].iloc[:2], hyp_df['Accuracy'].iloc[:2], color='red')\n",
    "\n",
    "# Annotating highest values\n",
    "x1, y1 = hyp_df['Learning rate'][0], hyp_df['Accuracy'][0]\n",
    "x2, y2 = hyp_df['Learning rate'][1], hyp_df['Accuracy'][1] \n",
    "\n",
    "plt.annotate('(' + str(x1.round(5)) + ', \\n' + str(y1.round(5)) + ')', [x1+0.00002, y1-0.0025])\n",
    "plt.annotate('(' + str(x2.round(5)) + ', \\n' + str(y2.round(5)) + ')', [x2+0.00002, y2-0.0025])\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Accuracies vs. learning rates in trial #2')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c957eaa",
   "metadata": {},
   "source": [
    "## 4.0 Evaluating best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a7ad6",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3469be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the best modles\n",
    "models = tuner_2.get_best_models(7)\n",
    "\n",
    "first, second, third, fourth, fifth, sixth, seventh = models[0], models[1], models[2], models[3], models[4],\\\n",
    "                                                      models[5], models[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function to predict and evaluate on Test set\n",
    "labels = ['Crazing', 'Inclusions', 'Patches', 'Pitted', 'Rolled', 'Scratches']\n",
    "\n",
    "def predictor(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test_classes, y_pred_classes))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test_classes, y_pred_classes, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087befba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbcf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18101b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating first model\n",
    "predictor(first, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5fdd5",
   "metadata": {},
   "source": [
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating second model\n",
    "predictor(second, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621830eb",
   "metadata": {},
   "source": [
    "### Model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating third model\n",
    "predictor(third, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad27fa",
   "metadata": {},
   "source": [
    "#### The remaining models did not result in better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b2c0e",
   "metadata": {},
   "source": [
    "#### Second model seems to perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48736",
   "metadata": {},
   "source": [
    "## 5.0 Image Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef6b28",
   "metadata": {},
   "source": [
    "### 4.1 Standard Score Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting image mean and image standard deviation from each individual image\n",
    "mean = np.mean(images)\n",
    "std = np.std(images)\n",
    "\n",
    "X_adj = (images - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5376e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape\n",
    "X_adj.shape, np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and (test, valid) sets to be split further\n",
    "X_train_adj, X_test_val_adj, y_train_adj, y_test_val = train_test_split(X_adj, labels, test_size=0.3, random_state=142)\n",
    "\n",
    "# Splitting (test, valid) set into seperate test and valid sets\n",
    "X_test_adj, X_val_adj, y_test_adj, y_val_adj = train_test_split(X_test_val_adj, y_test_val, test_size=0.5, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf240ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming shapes\n",
    "X_train_adj.shape, y_train_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming shapes\n",
    "X_val_adj.shape, y_val_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec10c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloning second model to train on normalized data\n",
    "norm_cnn = models.clone_model(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c45cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training normalized CNN\n",
    "history_norm_cnn = train_model(norm_cnn, X_train_adj, y_train_adj, X_val_adj, y_val_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix Classification report for Normalized CNN model\n",
    "predictor(norm_cnn, X_test_adj, y_test_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bca7d",
   "metadata": {},
   "source": [
    "### 4.2 Rotation 5ยบ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35232320",
   "metadata": {},
   "source": [
    "#### Rotating images might result in higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_5 = models.clone_model(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56505b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=5)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "cnn_5.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "history_cnn_5 = train_model(cnn_5, X_train_adj, y_train_adj, X_val_adj, y_val_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
